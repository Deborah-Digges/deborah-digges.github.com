{"componentChunkName":"component---src-templates-blog-template-js","path":"/2016/12/27/Traffic-Sign-Classification/","result":{"data":{"markdownRemark":{"html":"<p>The second project in the <a href=\"https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd013\">Self Driving Car Nano-degree</a> was the application of deep learning to the problem of traffic sign classification. Identifying traffic signs correctly and taking appropriate action is crucial to the operation of an autonomous vehicle.</p>\n<p>The project was markedly more difficult than the previous one of lane detection for several reasons including the steep learning curve of the <a href=\"https://www.tensorflow.org/\">Tensorflow</a> deep learning framework, the vast number of hyper-parameters that deep learning models have to tune and the extremely slow turn around time for model validation on CPUs which necessitates the setup of an environment with a powerful GPU either physically or using a cloud provider.</p>\n<p>We were provided with the <a href=\"http://benchmark.ini.rub.de/?section=gtsrb&#x26;subsection=dataset#Downloads\">German Traffic Signs</a> data set that contained about 40k training examples and 12k testing examples. The problem was one of classification which aims to assign the right class to a new image of a traffic sign by training on the provided pairs of traffic sign images and their labels. The project was broken down into:</p>\n<h3>1. Exploratory Data Analysis</h3>\n<p>The provided training data was examined mainly for the distribution of the various classes. The classes were found to be highly imbalanced indicating the need for data generation for the under-represented classes.</p>\n<h3>2. Data Pre-processing and Augmentation</h3>\n<p>The input images to the neural network went through a few pre-processing steps to help the gradient descent optimization for training the network. Pre-processing included:</p>\n<p>i.  <strong>Grey Scale Conversion</strong></p>\n<p>ii. <strong>Centering of images</strong> : The mean pixel value was subtracted from each pixel of the image to center the data around the origin</p>\n<p>iii. <strong>Normalization</strong> : This was done by dividing each dimension by its standard deviation once it was zero-centered. This is not strictly needed for images because the relative scales of pixels are already approximately equal. This process causes each feature to have a similar range so that our gradients don't go out of control (and that we only need one global learning rate multiplier).</p>\n<p>Additional data for under-represented classes was generated through a combination of the following techniques:</p>\n<ul>\n<li><strong>Translation</strong></li>\n<li><strong>Rotation</strong></li>\n<li><strong>Affine transformations</strong></li>\n</ul>\n<h3>3. Definition of CNN Architecture</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8103b4a12b325e8ad5f6d4d3d08895c0/3f009/NN.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 26%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAFABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3QQH/8QAFhAAAwAAAAAAAAAAAAAAAAAAABAh/9oACAEBAAEFAlT/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAY/An//xAAXEAEBAQEAAAAAAAAAAAAAAAABABFR/9oACAEBAAE/IddtZei//9oADAMBAAIAAwAAABCDz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQACAQUAAAAAAAAAAAAAAAEAIRExQVFhkf/aAAgBAQABPxBIGSx2g4WacdwzXhP/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Architecture\"\n        title=\"Architecture\"\n        src=\"/static/8103b4a12b325e8ad5f6d4d3d08895c0/4b190/NN.jpg\"\n        srcset=\"/static/8103b4a12b325e8ad5f6d4d3d08895c0/e07e9/NN.jpg 200w,\n/static/8103b4a12b325e8ad5f6d4d3d08895c0/066f9/NN.jpg 400w,\n/static/8103b4a12b325e8ad5f6d4d3d08895c0/4b190/NN.jpg 800w,\n/static/8103b4a12b325e8ad5f6d4d3d08895c0/e5166/NN.jpg 1200w,\n/static/8103b4a12b325e8ad5f6d4d3d08895c0/3f009/NN.jpg 1225w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"align-center\">Fig: CNN Architecture</div>\n<p>The model consisted of 2 convolutional layers followed by two fully connected layers. Several methods were employed for preventing over-fitting including:</p>\n<ul>\n<li><strong>Max Pooling</strong></li>\n<li><strong>Drop Outs</strong></li>\n<li><strong>L2 Regularization</strong></li>\n<li><strong>Validation Data set</strong></li>\n</ul>\n<h3>4. Training the model</h3>\n<p>Training on a CPU became quickly unwieldy and frustrating, so I set up an environment in AWS by following the instructions <a href=\"http://max-likelihood.com/2016/06/18/aws-tensorflow-setup/\">here</a>. Additionally, to set up jupyter on AWS and run Jupyter Notebooks remotely, I followed the instructions <a href=\"https://gist.github.com/iamatypeofwalrus/5183133\">here</a>. The model was trained for around 100 epochs resulting in validation accuracy of 99.7% and a test accuracy of 96.2%.</p>\n<h3>5. Testing on real world examples</h3>\n<p>The model was tested on images from the web and the probabilities of the top 5 predicted classes were plotted. For some of the classes the model was spot on:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/839e0c7423dd4a1db367dae1650248cc/f3a19/test-image.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 112.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAABYlAAAWJQFJUiTwAAACiElEQVQ4y51VS0uqURR1kP4IMfCX+B8U/BFRA00RmkgNA6EGQSMFQ4QI7pMm9w40IRo2sEKumvgo8lU+8kl+635r5/GqiNndsNnfOZ6zzjp7r300aJqG0Wgkzu/psZp7eXlBKpXCzc0N7u7uUCwWJRYKBWQzGfmt2+2CZsAKVqvV8PT0JJH+/PyMarWKerOJ0tcvyF9fo//29g5Yr9flRG7gqZeXl0gmkyiXy8Kg3W6j1+thMBgsPKz/8wc6uXsMx2PD9vY2DAYDjEYjrFYr/H4/LBYL1tbWZH53dxdNnQmBaZPUMOrjjg7YSP/BQNPeAd1ut2ykO51OnJ6ewuFwTOb29vZkoQJUeRYfA7b0PE4Yulwu2bi+vo6DgwOcn58jEAjAbDbL/M7ODlqt1lLAZjr9j6ECJLtEIoFoNIqLiwvY7XaZ93q9n2O4ubkp+To6OhJ5nJ2dSTw8PITJZMLW1pbkbSnDjM5QAW5sbMBms4mWaPF4XOLt7a3M+3w+qfCHV1aA+/v7YKUpHcqEDPmdz+fh8XhwfHwsC19fX1e7ciwWQzAYlNydnJxIDIfDiEQiCIVCuLq6QqVSQafTmQWckc1UUXgVOhlQ5I1GYxLZFazwcDgUcS+y3vdvaE8z/KjtWBB2EcXNQ5WTREvv3/rvX6gRUDGcyckCJ2C/3xfP5XLSkowPDw/IZrMo6JG3UOlYylAbn6rs8fFRJMWiqQeiqud3OO7zpYAKbJopAVggKoD5LZVKMib7lRjOA5MZgZlPVTiCqoJ9GpC5U5rk1WkUPQ/5NKB6aGlkyOsvWrfSiz1fHKXZ6RxPGH4km3kJ0SiTeUDlKzGcZ8piUI+L2P8XQ3aJKsr0vyX9L64qkN/YjD6PAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Architecture\"\n        title=\"Architecture\"\n        src=\"/static/839e0c7423dd4a1db367dae1650248cc/5a190/test-image.png\"\n        srcset=\"/static/839e0c7423dd4a1db367dae1650248cc/772e8/test-image.png 200w,\n/static/839e0c7423dd4a1db367dae1650248cc/e17e5/test-image.png 400w,\n/static/839e0c7423dd4a1db367dae1650248cc/5a190/test-image.png 800w,\n/static/839e0c7423dd4a1db367dae1650248cc/f3a19/test-image.png 1086w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"align-center\">Fig: Classification of New Image</div>\n<p>The model classifier mis-classified some images, but had the correct prediction within the top 5 predicted classes. For example, this 30km/h sign was mis-classified as an 80km/h sign:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3c4068e71cc138c8afc13659928f203b/587b0/wrong-classification.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 115.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAABYlAAAWJQFJUiTwAAACWElEQVQ4y51Va6/pQBTt//8fPpHgA9czHCEkxytycX0h1KvepS312nfWZqTqPHrOTiYzrc7ae621Zyh0j+v1+pjlcP9mmiZtt1vabDa02+34mYdhkGXbZO73pDgBnCBOcIQhNjWbTapUKlQul6lWq1G73aZGo0Gtfx36m89T+e2NFHKFLTKhCsxucF3X6SUul1vCWIzsapUUZJ7NZg8a3W6XCoUCdTodfl6v17RcLjnBYrEQ+y/Pie7PZiJOB1G9IjWR1TlpH49HnvENkg6HwxedJaARvwNC1Hq9TvP5/M7gwnrthcDYgOomk8nDlPP5/GyiGxCUEokEhUIhriKTyVA6nSa/30/j8Zji4sNisch0UaGzGz4EXK1W7FYymWSwQCBA0WiUfD4fpVIpBkdCyIIhNfwSEG2AikAtl8uxKUgAGSKRCAOCCVz2RLlUKlE2m6V+v0950U8x0QLhcJi1DQaDXPF0OuWE31KGNq1Wix0FncPhQKfTiYdlWfwelQIAZn1bISij2+HqZwF3wUTTtNcj6gZEWwCw1+uxq3BSzqqq0mg04t8AikrB4qkP7xUbaOxq5Xb0JEV52EEV9OQFgDUCLrvPuwzrT5Ts8vvtcvASoAxTwAgGgT7mqXiniXeqMFYTXrzcNl8NeQwhw2Aw4ARYj8UYirUumCheqnNfY9AYlcpjiWdVJNiKPlW8gDln6AtzQBkyyDWADa8VOgGxCdrhEMBIhOwMmPhjQLiOajAkINoLSaDvjwFBGRTRmxIQxiCB7kXDj0Bl7zrNQpJfafjZPyLuBMjxH7za3RExuo4HAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Architecture\"\n        title=\"Architecture\"\n        src=\"/static/3c4068e71cc138c8afc13659928f203b/5a190/wrong-classification.png\"\n        srcset=\"/static/3c4068e71cc138c8afc13659928f203b/772e8/wrong-classification.png 200w,\n/static/3c4068e71cc138c8afc13659928f203b/e17e5/wrong-classification.png 400w,\n/static/3c4068e71cc138c8afc13659928f203b/5a190/wrong-classification.png 800w,\n/static/3c4068e71cc138c8afc13659928f203b/587b0/wrong-classification.png 970w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"align-center\">Fig: Mis-classification of 30km/h sign</div>\n<p>Overall, this project was a great learning experience. However, there does still exist several areas for improvement. The project in it's current state can he found <a href=\"https://github.com/Deborah-Digges/SDC-ND/blob/master/P2-traffic-signs/Traffic_Signs_Recognition.ipynb\">here</a>.</p>","frontmatter":{"title":"Traffic Sign Classification using Deep Learning"},"fields":{"date":"2016-12-27","slug":"2016/12/27/Traffic-Sign-Classification/"}}},"pageContext":{"slug":"2016/12/27/Traffic-Sign-Classification/","date":"2016-12-27"}},"staticQueryHashes":[]}